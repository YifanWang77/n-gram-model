{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980954a-4535-4e6d-b5f3-0479cd2d3dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03df533-34cb-4f8a-b770-9c6dfd97ac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5606b8-4c22-4221-b4ea-b658ab1b8926",
   "metadata": {},
   "source": [
    "# 1 Data collection and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4465b649-641f-4a85-a304-9efaca2b9abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "\n",
    "text = gutenberg.raw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd9f98d-3ccc-41e7-8129-ac3e8b6c7bb3",
   "metadata": {},
   "source": [
    "## Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62331a84-d4e9-4a39-abd4-cf256b9e320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515860b-e714-4bdd-bb89-c9e13c9b9ea9",
   "metadata": {},
   "source": [
    "## Removing Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75193490-169f-4512-8925-eab2d2b4073a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5384e2ea-0152-4898-b732-d73d0041bbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\".join([char for char in text if char not in string.punctuation])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22fdb45-09b2-4d6f-85d9-e955aab0f913",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fefa4624-23ca-4e4d-92a3-583217847842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "#sent_tokens = sent_tokenize(text)\n",
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de5d4a-0bff-4ac2-9f36-91a3a257cb6d",
   "metadata": {},
   "source": [
    "## Stopword Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee26d0e3-c223-4758-98e6-0cc4b79a4465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86ba0572-f655-428d-87c4-227cea4df513",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "filtered_tokens = [token for token in tokens if token not in stop_words] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941802e-8150-49a9-8e90-a1264d6d91e1",
   "metadata": {},
   "source": [
    "## lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd723943-c226-405d-8f16-2e4b3fd88815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c57d321-e15f-48df-8037-45b9aaad9b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "lemmas = [wnl.lemmatize(token) for token in filtered_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38589424-fbad-4c6c-96f1-5cc781db1f0e",
   "metadata": {},
   "source": [
    "# 2 Model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "184f854d-7d78-4fed-b0ad-a79c72802da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate trigrams\n",
    "trigrams = list(nltk.ngrams(filtered_tokens, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5de3a556-6c7c-4ed9-930f-8f9410e5e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the frequency of each trigram\n",
    "import collections\n",
    "trigram_freqs = collections.Counter(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "300138d8-a94a-4656-8134-a2086edf79e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = list(nltk.ngrams(lemmas, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98f3a5c4-bf32-4089-bb85-24a167c60871",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "bigram_freqs = collections.Counter(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd5417e-bbc3-41ff-88a2-58c9dcf9d922",
   "metadata": {},
   "source": [
    "## Probability Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce75356c-0cd7-4c3b-b141-96ea13d43ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probabilities(word):\n",
    "    probabilities = {}\n",
    "    for bigram in bigrams:\n",
    "        # Form the trigram from the bigram and the word\n",
    "        trigram = bigram + (word,)\n",
    "\n",
    "        # Get the frequency of the trigram\n",
    "        trigram_frequency = trigram_freqs.get(trigram, 0)\n",
    "\n",
    "        # Get the frequency of the bigram\n",
    "        bigram_frequency = bigram_freqs.get(bigram, 0)\n",
    "\n",
    "        if bigram_frequency == 0:\n",
    "            probabilities[bigram] = 0\n",
    "        else:\n",
    "            probability = trigram_frequency / bigram_frequency\n",
    "            probabilities[bigram] = probability\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb153f69-7940-40db-8a3b-4eb7ed794522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8689458689458689"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "result = calculate_probabilities('god')\n",
    "result.get(('lord', 'thy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878b9496-520b-4aa0-925b-82b7d6f2fab8",
   "metadata": {},
   "source": [
    "## Next Word Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecab080b-c2ef-45c9-8599-2ab9a9918271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted next word is: god\n"
     ]
    }
   ],
   "source": [
    "def predict_next_word(sequence):\n",
    "    # Tokenize the sequence to handle multiple words\n",
    "    tokens = sequence.split()\n",
    "\n",
    "    # Check if we have at least 2 tokens to work with\n",
    "    if len(tokens) < 2:\n",
    "        return \"Error: Need at least two words for prediction\"\n",
    "\n",
    "    # Get the last two words\n",
    "    last_two_words = tuple(tokens[-2:])\n",
    "\n",
    "    # Find all possible next words\n",
    "    possible_next_words = {trigram[2]: freq for trigram, freq in trigram_freqs.items() if trigram[:2] == last_two_words}\n",
    "\n",
    "    # If no possible words are found\n",
    "    if not possible_next_words:\n",
    "        return \"No prediction available\"\n",
    "\n",
    "    # Get the most frequent next word\n",
    "    predicted_word = max(possible_next_words, key=possible_next_words.get)\n",
    "\n",
    "    return predicted_word\n",
    "\n",
    "# test\n",
    "sequence = \"lord thy\"\n",
    "predicted_word = predict_next_word(sequence)\n",
    "print(f\"The predicted next word is: {predicted_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2cbc81-cfa1-4bef-b01f-7e52577a6b77",
   "metadata": {},
   "source": [
    "## Sentence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78b52b5c-28da-471d-ab06-f904e200e469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(prefix, sentence_length):\n",
    "    if len(prefix.split()) != 2:\n",
    "        return \"Error: Prefix must contain exactly two words for a trigram model.\"\n",
    "\n",
    "    else:\n",
    "        sentence = prefix.split()\n",
    "        while len(sentence) < sentence_length:\n",
    "            last_two_words = tuple(sentence[-2:])\n",
    "            possible_next_words = {trigram[2]: freq for trigram, freq in trigram_freqs.items() if trigram[:2] == last_two_words}\n",
    "\n",
    "            if not possible_next_words:\n",
    "                break\n",
    "            next_word = max(possible_next_words, key=possible_next_words.get)\n",
    "            sentence.append(next_word)\n",
    "\n",
    "        return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccba2c47-e0e2-4028-af84-272764dafd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lord thy god hath given us inheritance fields vineyards wilt thou go battle children benjamin came according families cities villages'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "sentence_generation(\"lord thy\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e501d5e7-d637-4618-a634-411ce21e7c1a",
   "metadata": {},
   "source": [
    "## Somoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0878f7ac-89c4-4c6b-a3a9-48e5adf0e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation_with_smoothing(prefix, sentence_length):\n",
    "    vocab_size = len(set(lemmas))\n",
    "    \n",
    "    if len(prefix.split()) != 2:\n",
    "        return \"Error: Prefix must contain exactly two words for a trigram model.\"\n",
    "\n",
    "    sentence = prefix.split()\n",
    "    while len(sentence) < sentence_length:\n",
    "        last_two_words = tuple(sentence[-2:])\n",
    "\n",
    "        # Initialize the best word and its max probability\n",
    "        best_next_word = None\n",
    "        max_probability = 0\n",
    "\n",
    "        # Try every possible next word in the vocabulary\n",
    "        for possible_next_word in lemmas:\n",
    "            # Create a potential trigram with the last two words and the current possible next word\n",
    "            trigram = last_two_words + (possible_next_word,)\n",
    "\n",
    "            # Apply Laplace smoothing\n",
    "            trigram_freq = trigram_freqs.get(trigram, 0) + 1\n",
    "            bigram_freq = bigram_freqs.get(last_two_words, 0) + vocab_size\n",
    "            probability = trigram_freq / bigram_freq\n",
    "\n",
    "            # Update the best next word based on the highest probability\n",
    "            if probability > max_probability:\n",
    "                max_probability = probability\n",
    "                best_next_word = possible_next_word\n",
    "\n",
    "        # Break if no valid next word is found\n",
    "        if not best_next_word:\n",
    "            break\n",
    "\n",
    "        sentence.append(best_next_word)\n",
    "\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd9efea7-97f4-4e8e-a3d8-03a8117fafe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lord thy god hath given us spirit spirit lord came unto saying thus saith lord god israel behold bring evil'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test\n",
    "sentence_generation_with_smoothing(\"lord thy\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53199ec3-2b1a-4c93-9e13-fc92fe2eb089",
   "metadata": {},
   "source": [
    "# Testing and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb178b8c-4c42-47fa-a181-b8611fcff6a2",
   "metadata": {},
   "source": [
    "## Next word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10101a86-b7b9-46fb-91da-7bc43f5cb92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams_for_test= bigrams[100:1000:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a57e77e2-b487-4d16-aea9-6af98633fb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['liked highly',\n",
       " 'friend emma',\n",
       " 'promoted match',\n",
       " 'marriage left',\n",
       " 'mile miss',\n",
       " 'temper talent',\n",
       " 'lawn shrubbery',\n",
       " 'body used',\n",
       " 'deal happier',\n",
       " 'humour might',\n",
       " 'james like',\n",
       " 'obliged glad',\n",
       " 'go see',\n",
       " 'highbury frequent',\n",
       " 'come late',\n",
       " 'joy pretty',\n",
       " 'troublesome creature',\n",
       " 'knightley fact']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_for_pred = [' '.join(bigram) for bigram in bigrams_for_test]\n",
    "sequences_for_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "763eeb84-659d-41cb-bf44-3784185f3e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "liked highly esteeming\n",
      "friend emma first\n",
      "promoted match black\n",
      "marriage left yet\n",
      "mile miss taylor\n",
      "temper talent emma\n",
      "lawn shrubbery emma\n",
      "body used hating\n",
      "deal happier mr\n",
      "humour might emma\n",
      "james like put\n",
      "obliged glad think\n",
      "go see house\n",
      "highbury frequent visitor\n",
      "come late year\n",
      "joy pretty well\n",
      "troublesome creature said\n",
      "knightley fact one\n"
     ]
    }
   ],
   "source": [
    "for sequence in sequences_for_pred:\n",
    "    print(sentence_generation_with_smoothing(sequence, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe17b9-dd97-4429-992e-39a1fbcd12ff",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16e5089c-2012-4263-b3aa-de5a3b3b144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = text.split(\"\\n\")\n",
    "segments = [segment for segment in segments if segment.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30dd3290-a0e2-40c3-bdf3-1ef59260e129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happier if she had spent all the rest of her life at hartfield',\n",
       " 'an egg boiled very soft is not unwholesome  serle understands boiling',\n",
       " 'to a very good purpose for she found her decidedly more sensible',\n",
       " 'of her with more voluntary praise than emma had ever heard before',\n",
       " 'in creating  this is a connexion which offers nothing but good',\n",
       " 'still however though every thing had not been accomplished',\n",
       " 'were actually at hartfield he was not able to make more than',\n",
       " 'putting an end to his extreme solicitude about her  she was vexed',\n",
       " 'it was rather too late in the day to set about being simpleminded',\n",
       " 'we will call in mr perry  the expense shall not be thought of',\n",
       " 'i did not know what to do  i was sitting near the doorelizabeth saw',\n",
       " 'if you were never particularly struck by her manners before',\n",
       " 'to betray any imperfection which could be concealed',\n",
       " 'presently mr knightley looked back and came and sat down by her',\n",
       " 'new pianoforte  do put up your horse at the crown and come in',\n",
       " 'is really interested in the absentshe will tell me every thing',\n",
       " 'and i must do my caro sposo the justice to say that he need not',\n",
       " 'exert our authority',\n",
       " 'which nobody had inclination to pay and she was herself',\n",
       " 'thing equal to the comfort and stylecandles everywherei was telling']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_sentences = segments[100:10000:500]\n",
    "reference_sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bfb3868f-6336-4189-b909-ce0c3b46306e",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_two_words = [sentence.split()[:2] for sentence in reference_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5abf7550-87e2-4b07-b2c3-4b6ab529b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_for_test = [' '.join(words) for words in first_two_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dca0471-057b-49b4-a353-7916797854ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sentences = []\n",
    "for sequence in sequence_for_test:\n",
    "    generated_sentences.append(sentence_generation_with_smoothing(sequence, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a29b1f10-2712-48cf-8bbf-179019f3582f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happier if emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'an egg emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'to a emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'of her emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'in creating emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'still however happy fancy came christ child born unto thee thou shalt make unto people',\n",
       " 'were actually emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'putting an emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'it was emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'we will emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'i did emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'if you emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'to betray emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'presently mr knightley would much better thing matrimony together chance happen woman single seven twenty',\n",
       " 'new pianoforte put horse crown come well said syme seriously promise swore god would make',\n",
       " 'is really emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'and i emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'exert our emma emma could feel man may come unto thee thou shalt make unto',\n",
       " 'which nobody emma want marry daughter lived emma guessed little show resentment towards jane give',\n",
       " 'thing equal comfort stylecandles everywherei telling grandmama janethere little disappointment baked emma emma could feel']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26e08253-0fbf-4a48-b861-bacca578ec6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qgrams = list(nltk.ngrams(filtered_tokens, 4))\n",
    "trigrams = list(nltk.ngrams(lemmas, 3))\n",
    "\n",
    "qgram_freqs = collections.Counter(qgrams)\n",
    "trigram_freqs = collections.Counter(trigrams)\n",
    "\n",
    "def calculate_probabilities(word):\n",
    "    probabilities = {}\n",
    "    for trigram in trigrams:\n",
    "        # Form the trigram from the bigram and the word\n",
    "        qgram = trigram + (word,)\n",
    "\n",
    "        # Get the frequency of the trigram\n",
    "        qgram_frequency = qgram_freqs.get(qgram, 0)\n",
    "\n",
    "        # Get the frequency of the bigram\n",
    "        trigram_frequency = trigram_freqs.get(trigram, 0)\n",
    "\n",
    "        if trigram_frequency == 0:\n",
    "            probabilities[trigram] = 0\n",
    "        else:\n",
    "            probability = qgram_frequency / trigram_frequency\n",
    "            probabilities[trigram] = probability\n",
    "    return probabilities\n",
    "\n",
    "def sentence_generation_with_smoothing_4(prefix, sentence_length):\n",
    "    vocab_size = len(set(lemmas))\n",
    "    \n",
    "    if len(prefix.split()) != 3:\n",
    "        return \"Error: Prefix must contain exactly three words for a qgram model.\"\n",
    "\n",
    "    sentence = prefix.split()\n",
    "    while len(sentence) < sentence_length:\n",
    "        last_three_words = tuple(sentence[-3:])\n",
    "\n",
    "        # Initialize the best word and its max probability\n",
    "        best_next_word = None\n",
    "        max_probability = 0\n",
    "\n",
    "        # Try every possible next word in the vocabulary\n",
    "        for possible_next_word in lemmas:\n",
    "            # Create a potential trigram with the last two words and the current possible next word\n",
    "            qgram = last_three_words + (possible_next_word,)\n",
    "\n",
    "            # Apply Laplace smoothing\n",
    "            qgram_freq = qgram_freqs.get(qgram, 0) + 1\n",
    "            trigram_freq = trigram_freqs.get(last_three_words, 0) + vocab_size\n",
    "            probability = qgram_freq / trigram_freq\n",
    "\n",
    "            # Update the best next word based on the highest probability\n",
    "            if probability > max_probability:\n",
    "                max_probability = probability\n",
    "                best_next_word = possible_next_word\n",
    "\n",
    "        # Break if no valid next word is found\n",
    "        if not best_next_word:\n",
    "            break\n",
    "\n",
    "        sentence.append(best_next_word)\n",
    "\n",
    "    return ' '.join(sentence)\n",
    "\n",
    "\n",
    "segments = text.split(\"\\n\")\n",
    "segments = [segment for segment in segments if segment.strip()]\n",
    "\n",
    "reference_sentences = segments[100:1000:50]\n",
    "reference_sentences \n",
    "\n",
    "first_three_words = [sentence.split()[:3] for sentence in reference_sentences]\n",
    "sequence_for_test_4 = [' '.join(words) for words in first_three_words]\n",
    "\n",
    "generated_sentences = []\n",
    "for sequence in sequence_for_test_4:\n",
    "    generated_sentences.append(sentence_generation_with_smoothing_4(sequence, 15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0d00c71a-06bd-424a-b883-3f0ee9a472fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['happier', 'if', 'she'],\n",
       " ['he', 'lived', 'about'],\n",
       " ['behaved', 'charmingly', 'every'],\n",
       " ['ladys', 'mind', 'but'],\n",
       " ['indisposed', 'for', 'any'],\n",
       " ['as', 'miss', 'taylor'],\n",
       " ['and', 'a', 'most'],\n",
       " ['being', 'seen', 'with'],\n",
       " ['for', 'nothing', 'the'],\n",
       " ['with', 'a', 'fine'],\n",
       " ['an', 'egg', 'boiled'],\n",
       " ['every', 'thing', 'in'],\n",
       " ['to', 'be', 'a'],\n",
       " ['six', 'years', 'hence'],\n",
       " ['and', 'walking', 'a'],\n",
       " ['of', 'being', 'silent'],\n",
       " ['she', 'feared', 'it'],\n",
       " ['emma', 'has', 'been']]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_three_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ad0ca840-6de1-4060-9982-9071392d9366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happier if she emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'he lived about emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'behaved charmingly every body punctual every body best emma emma emma emma emma emma emma',\n",
       " 'ladys mind but emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'indisposed for any emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'as miss taylor emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'and a most emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'being seen with emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'for nothing the emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'with a fine emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'an egg boiled emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'every thing in emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'to be a emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'six years hence could meet good sort young woman rank little money might desirable six',\n",
       " 'and walking a emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'of being silent emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'she feared it emma emma emma emma emma emma emma emma emma emma emma emma',\n",
       " 'emma has been emma emma emma emma emma emma emma emma emma emma emma emma']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28458fd6-eb3b-486d-a319-34389c068d7f",
   "metadata": {},
   "source": [
    "When n equals 3 or 4, the model failed to produce coherent sentences. Consider predicting the next word based on its distribution rather than adhering to a greedy approach.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4925439-e43d-4a31-862f-d18dd41104c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices\n",
    "\n",
    "def sentence_generation_with_smoothing(prefix, sentence_length):\n",
    "    vocab_size = len(set(lemmas))\n",
    "    \n",
    "    if len(prefix.split()) != 2:\n",
    "        return \"Error: Prefix must contain exactly two words for a trigram model.\"\n",
    "\n",
    "    sentence = prefix.split()\n",
    "    while len(sentence) < sentence_length:\n",
    "        last_two_words = tuple(sentence[-2:])\n",
    "\n",
    "        # Collect all potential next words and their probabilities\n",
    "        next_words_probs = []\n",
    "        for possible_next_word in lemmas:\n",
    "            trigram = last_two_words + (possible_next_word,)\n",
    "            trigram_freq = trigram_freqs.get(trigram, 0) + 1\n",
    "            bigram_freq = bigram_freqs.get(last_two_words, 0) + vocab_size\n",
    "            probability = trigram_freq / bigram_freq\n",
    "            next_words_probs.append((possible_next_word, probability))\n",
    "\n",
    "        # Normalize the probabilities\n",
    "        total_prob = sum(prob for _, prob in next_words_probs)\n",
    "        normalized_probs = [(word, prob / total_prob) for word, prob in next_words_probs]\n",
    "\n",
    "        # Choose the next word based on the distribution\n",
    "        next_word = choices([word for word, _ in normalized_probs], \n",
    "                            [prob for _, prob in normalized_probs], k=1)[0]\n",
    "\n",
    "        # Append the chosen word to the sentence\n",
    "        if next_word:\n",
    "            sentence.append(next_word)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    return ' '.join(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35b16f38-34fd-4752-84df-c5a3b7d9ec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sentences = []\n",
    "for sequence in sequence_for_test:\n",
    "    generated_sentences.append(sentence_generation_with_smoothing(sequence, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ecde4660-601e-480a-8e30-b189085a6079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['happier if rock old avoided consequence 102 miss benjamin abstract scholar naples corp amazement brother',\n",
       " 'an egg dislike let son strong margaret eye twenty beyond must longer quantity sure house',\n",
       " 'to a would topic eye coil went mr ask people eat jesus daughter 2517 park',\n",
       " 'of her wind though myriad spared unto however seven men keeper eternal pause jerusalem thou',\n",
       " 'in creating thou faithfully time way thing mind made hovering admitted whenever one footstep visiting',\n",
       " 'still however cometh ripe abruptly close one unto thine even tear skin ive never narrative',\n",
       " 'were actually order sihon give hand maid egypt delight year fellow man terrible relate manner',\n",
       " 'putting an 1928 goodbye done however earnestness egypt unto little two smith sword lady invitation',\n",
       " 'it was nay mr thus forwardcame dare puzzled eye prayer piteous hand infirm watched overcome',\n",
       " 'we will cast winter behold daniel scattered play produced poured tree unto work circlings unworthy',\n",
       " 'i did knew find sanctify 15 thus one something end practise insomuch five city israel',\n",
       " 'if you unto upset cried another word question said returned follow said end brake offering',\n",
       " 'to betray le truth watchcoat put louisas mac putting said monday made fancy word hundred',\n",
       " 'presently mr say lord darkness mr field 1111 said highest child epistle three old reached',\n",
       " 'new pianoforte quietly terrible army shop even presence known windowshutter complaint dear law let bliss',\n",
       " 'is really coat hard england thee knew friendship king strikingly fire life went woman negligent',\n",
       " 'and i lady deep worshipped sword bid presented hearing magic man attended ark loss somehow',\n",
       " 'exert our effect great every little halleluiahs devil case splendid side like son seem find',\n",
       " 'which nobody richardson betrayed 1325 kept unleavened soon motion croft fire host face forest mother',\n",
       " 'thing equal whatsoever miss case 16 unto better thy canaan husband barrenness two wealth perjury']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e442abd-060a-4e99-a3d6-9445461fce98",
   "metadata": {},
   "source": [
    "The results look a little better now, at least there's not too much repetition of the same word. But most of the sentences still don't make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f340983-910a-4388-8a18-8f856ba58e9a",
   "metadata": {},
   "source": [
    "# UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1c5a32c3-7e3c-4c11-8a3c-461952dcdc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk\n",
    "\n",
    "def generate_sentence():\n",
    "    prefix = prefix_entry.get()\n",
    "    try:\n",
    "        sentence_length = int(length_entry.get())\n",
    "    except ValueError:\n",
    "        result_label.config(text=\"Error: Sentence length must be a number.\")\n",
    "        return\n",
    "\n",
    "    generated_sentence = sentence_generation_with_smoothing(prefix, sentence_length)\n",
    "    result_label.config(text=generated_sentence)\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Trigram Sentence Generator\")\n",
    "\n",
    "# Create and place widgets\n",
    "prefix_label = ttk.Label(root, text=\"Enter Prefix:\")\n",
    "prefix_label.pack()\n",
    "\n",
    "prefix_entry = ttk.Entry(root)\n",
    "prefix_entry.pack()\n",
    "\n",
    "length_label = ttk.Label(root, text=\"Enter Sentence Length:\")\n",
    "length_label.pack()\n",
    "\n",
    "length_entry = ttk.Entry(root)\n",
    "length_entry.pack()\n",
    "\n",
    "generate_button = ttk.Button(root, text=\"Generate Sentence\", command=generate_sentence)\n",
    "generate_button.pack()\n",
    "\n",
    "result_label = ttk.Label(root, text=\"\")\n",
    "result_label.pack()\n",
    "\n",
    "# Run the application\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
